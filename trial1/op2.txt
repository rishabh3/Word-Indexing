5
In mathematics and computer science, an algorithm (Listeni/ˈælɡərɪðəm/ AL-gə-ri-dhəm) is a self-contained step-by-step set of operations to be performed. Algorithms perform calculation, data processing, and/or automated reasoning tasks.

An algorithm is an effective method that can be expressed within a finite amount of space and time[1] and in a well-defined formal language[2] for calculating a function.[3] Starting from an initial state and initial input (perhaps empty),[4] the instructions describe a computation that, when executed, proceeds through a finite[5] number of well-defined successive states, eventually producing "output"[6] and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.[7]

The concept of algorithm has existed for centuries; however, a partial formalization of what would become the modern algorithm began with attempts to solve the Entscheidungsproblem (the "decision problem") posed by David Hilbert in 1928. Subsequent formalizations were framed as attempts to define "effective calculability"[8] or "effective method";[9] those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's "Formulation 1" of 1936, and Alan Turing's Turing machines of 1936–7 and 1939. Giving a formal definition of algorithms, corresponding to the intuitive notion, remains a challenging problem.[10]
Etymologically, the word 'algorithm' is a combination of the Latin word algorismus, named after Al-Khwarizmi, a 9th century Persian mathematician.,[11] and the Greek word arithmos, i.e. αριθμός, meaning "number". In English, it was first used in about 1230 and then by Chaucer in 1391. English adopted the French term, but it wasn't until the late 19th century that "algorithm" took on the meaning that it has in modern English.

Another early use of the word is from 1240, in a manual titled Carmen de Algorismo composed by Alexandre de Villedieu.
 It begins thus:

    Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.

which translates as:

    Algorism is the art by which at present we use those Indian figures, which number two times five.

The poem is a few hundred lines long and summarizes the art of calculating with the new style of Indian dice, or Talibus Indorum, or Hindu numerals.

An informal definition could be "a set of rules that precisely defines a sequence of operations."[12] which would include all computer programs, including programs that do not perform numeric calculations. Generally, a program is only an algorithm if it stops eventually.[13]

A prototypical example of an algorithm is the Euclidean algorithm to determine the maximum common divisor of two integers; an example (there are others) is described by the flow chart above and as an example in a later section.

Boolos & Jeffrey (1974, 1999) offer an informal meaning of the word in the following quotation:

    No human being can write fast enough, or long enough, or small enough† ( †"smaller and smaller without limit ...you'd be trying to write on molecules, on atoms, on electrons") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.[14]

An "enumerably infinite set" is one whose elements can be put into one-to-one correspondence with the integers. Thus, Boolos and Jeffrey are saying that an algorithm implies instructions for a process that "creates" output integers from an arbitrary "input" integer or integers that, in theory, can be arbitrarily large.
 Thus an algorithm can be an algebraic equation such as y = m + n – two arbitrary "input variables" m and n that produce an output y. But various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):

    Precise instructions (in language understood by "the computer")[15] for a fast, efficient, "good"[16] process that specifies the "moves" of "the computer" (machine or human, equipped with the necessary internally contained information and capabilities)[17] to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and = ... and "effectively"[18] produce, in a "reasonable" time,[19] output-integer y at a specified place and in a specified format.

The concept of algorithm is also used to define the notion of decidability. That notion is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related with our customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.
Algorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform (in a specific order) to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987) and Gurevich (2000):

    Minsky: "But we will also maintain, with Turing . . .
 that any procedure which could "naturally" be called effective, can in fact be realized by a (simple) machine. Although this may seem extreme, the arguments . . . in its favor are hard to refute".[20]

    Gurevich: "...Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine ... according to Savage [1987], an algorithm is a computational process defined by a Turing machine".[21]

Typically, when an algorithm is associated with processing information, data are read from an input source, written to an output device, and/or stored for further processing. Stored data are regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.


For some such computational process, the algorithm must be rigorously defined: specified in the way it applies in all possible circumstances that could arise. That is, any conditional steps must be systematically dealt with, case-by-case; the criteria for each case must be clear (and computable).

Because an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting "from the top" and going "down to the bottom", an idea that is described more formally by flow of control.

So far, this discussion of the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception, and it attempts to describe a task in discrete, "mechanical" means. Unique to this conception of formalized algorithms is the assignment operation, setting the value of a variable. It derives from the intuition of "memory" as a scratchpad. There is an example below of such an assignment.

For some alternate conceptions of what constitutes an algorithm see functional programming and logic programming.

In
mathematics
and
computer
science,
an
algorithm
(Listeni/ˈælɡərɪðəm/
AL-gə-ri-dhəm)
is
a
self-contained
step-by-step
set
of
operations
to
be
performed
Algorithms
perform
calculation,
data
processing,
and/or
automated
reasoning
tasks
An
effective
method
that
can
expressed
within
finite
amount
space
time[1]
in
well-defined
formal
language[2]
for
calculating
function
[3]
Starting
from
initial
state
input
(perhaps
empty),[4]
the
instructions
describe
computation
that,
when
executed,
proceeds
through
finite[5]
number
successive
states,
eventually
producing
"output"[6]
terminating
at
final
ending
The
transition
one
next
not
necessarily
deterministic;
some
algorithms,
known
as
randomized
incorporate
random
[7]
concept
has
existed
centuries;
however,
partial
formalization
what
would
become
modern
began
with
attempts
solve
Entscheidungsproblem
(the
"decision
problem")
posed
by
David
Hilbert
1928
Subsequent
formalizations
were
framed
define
"effective
calculability"[8]
or
method";[9]
those
included
Gödel–Herbrand–Kleene
recursive
functions
1930,
1934
1935,
Alonzo
Church's
lambda
calculus
1936,
Emil
Post's
"Formulation
1"
Alan
Turing's
Turing
machines
1936–7
1939
Giving
definition
corresponding
intuitive
notion,
remains
challenging
problem
[10]
Etymologically,
word
'algorithm'
combination
Latin
algorismus,
named
after
Al-Khwarizmi,
9th
century
Persian
mathematician
,[11]
Greek
arithmos,
i
e
αριθμός,
meaning
"number"
English,
it
was
first
used
about
1230
then
Chaucer
1391
English
adopted
French
term,
but
wasn't
until
late
19th
"algorithm"
took
on
Another
early
use
1240,
manual
titled
Carmen
de
Algorismo
composed
Alexandre
Villedieu
It
begins
thus:
Haec
algorismus
ars
praesens
dicitur,
qua
/
Talibus
Indorum
fruimur
bis
quinque
figuris
which
translates
as:
Algorism
art
present
we
Indian
figures,
two
times
five
poem
few
hundred
lines
long
summarizes
new
style
dice,
Indorum,
Hindu
numerals
informal
could
"a
rules
precisely
defines
sequence
"[12]
include
all
programs,
including
programs
do
numeric
calculations
Generally,
program
only
if
stops
[13]
A
prototypical
example
Euclidean
determine
maximum
common
divisor
integers;
(there
are
others)
described
flow
chart
above
later
section
Boolos
&
Jeffrey
(1974,
1999)
offer
following
quotation:
No
human
being
write
fast
enough,
small
enough†
(
†"smaller
smaller
without
limit
you'd
trying
molecules,
atoms,
electrons")
list
members
enumerably
infinite
writing
out
their
names,
another,
notation
But
humans
something
equally
useful,
case
certain
sets:
They
give
explicit
determining
nth
member
set,
arbitrary
n
Such
given
quite
explicitly,
form
they
followed
computing
machine,
who
capable
carrying
very
elementary
symbols
[14]
"enumerably
set"
whose
elements
put
into
one-to-one
correspondence
integers
Thus,
saying
implies
process
"creates"
output
"input"
integer
theory,
arbitrarily
large
Thus
algebraic
equation
such
y
=
m
+
–
"input
variables"
produce
various
authors'
notion
indicate
much
more
than
this,
order
(for
addition
example):
Precise
(in
language
understood
"the
computer")[15]
fast,
efficient,
"good"[16]
specifies
"moves"
computer"
(machine
human,
equipped
necessary
internally
contained
information
capabilities)[17]
find,
decode,
integers/symbols
n,
"effectively"[18]
produce,
"reasonable"
time,[19]
output-integer
specified
place
format
also
decidability
That
central
explaining
how
systems
come
starting
axioms
logic,
time
requires
complete
cannot
measured,
apparently
related
our
customary
physical
dimension
From
uncertainties,
characterize
ongoing
work,
stems
unavailability
suits
both
concrete
sense)
abstract
usage
term
essential
way
computers
Many
contain
algorithms
detail
specific
should
order)
carry
task,
employees'
paychecks
printing
students'
report
cards
considered
any
simulated
Turing-complete
system
Authors
assert
this
thesis
Minsky
(1967),
Savage
(1987)
Gurevich
(2000):
Minsky:
"But
will
maintain,
procedure
"naturally"
called
effective,
fact
realized
(simple)
machine
Although
may
seem
extreme,
arguments
its
favor
hard
refute"
[20]
Gurevich:
"
argument
his
justifies
stronger
thesis:
every
according
[1987],
computational
defined
machine"
[21]
Typically,
associated
processing
information,
read
source,
written
device,
stored
further
Stored
regarded
part
internal
entity
performing
practice,
structures
For
process,
must
rigorously
defined:
applies
possible
circumstances
arise
is,
conditional
steps
systematically
dealt
with,
case-by-case;
criteria
each
clear
(and
computable)
Because
precise
steps,
always
crucial
functioning
Instructions
usually
assumed
listed
"from
top"
going
"down
bottom",
idea
formally
control
So
far,
discussion
premises
imperative
programming
This
most
conception,
task
discrete,
"mechanical"
means
Unique
conception
formalized
assignment
operation,
setting
value
variable
derives
intuition
"memory"
scratchpad
There
below
alternate
conceptions
constitutes
see
functional
logic
The total unique words found in the file is :629